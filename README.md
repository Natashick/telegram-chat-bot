# Telegram PDF Chatbot
## Intelligente Dokumentensuche mit lokaler KI

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://www.docker.com/)

Ein datenschutzfreundlicher Telegram-Bot fÃ¼r **semantische Suche und Frage-Antwort** Ã¼ber PDF-Dokumente. Nutzt lokales LLM (Ollama) und ChromaDB fÃ¼r vollstÃ¤ndig lokale, KI-gestÃ¼tzte Dokumentenanalyse.

---

## ğŸŒŸ Highlights

- ğŸ” **Semantische Suche**: Bedeutungsbasiertes VerstÃ¤ndnis, nicht nur Keywords
- ğŸ¤– **Lokales LLM**: VollstÃ¤ndige Datenkontrolle, keine externen APIs
- ğŸ“š **Multi-Dokument**: Durchsucht mehrere PDFs gleichzeitig
- ğŸŒ **Mehrsprachig**: Deutsch & Englisch
- ğŸ”’ **Datenschutz**: 100% lokale Verarbeitung
- ğŸ“± **Telegram-Integration**: Nutzen Sie Ihre gewohnte App
- ğŸ³ **Docker-Ready**: Einfaches Deployment

---

## ğŸ“– Dokumentation

**VollstÃ¤ndige Dokumentation verfÃ¼gbar in `/docs/`**

### Schnellstart nach Zielgruppe:

| Sie sind... | Starten Sie hier |
|-------------|------------------|
| ğŸ‘¤ **Endnutzer** | [Benutzerhandbuch (Deutsch)](docs/customer/BENUTZERHANDBUCH.md) |
| ğŸ”§ **Administrator** | [Deployment Guide](docs/technical/02_DEPLOYMENT_GUIDE.md) |
| ğŸ’» **Entwickler** | [System Architecture](docs/technical/01_SYSTEM_ARCHITECTURE.md) |
| ğŸ“Š **Projektmanager** | [Lastenheft](docs/lastenheft/LASTENHEFT.md) |

### DokumentationsÃ¼bersicht:

- **[ğŸ“š Dokumentations-Index](docs/README.md)** - Kompletter Ãœberblick
- **[ğŸ—ï¸ System Architecture](docs/technical/01_SYSTEM_ARCHITECTURE.md)** - Technisches Design
- **[ğŸš€ Deployment Guide](docs/technical/02_DEPLOYMENT_GUIDE.md)** - Installation & Betrieb
- **[ğŸ”Œ API Documentation](docs/technical/03_API_DOCUMENTATION.md)** - Schnittstellen-Referenz
- **[âš™ï¸ Configuration Reference](docs/technical/04_CONFIGURATION.md)** - Alle Konfigurationsoptionen
- **[ğŸ“‹ Lastenheft](docs/lastenheft/LASTENHEFT.md)** - Anforderungsspezifikation
- **[ğŸ“‹ Pflichtenheft](docs/pflichtenheft/PFLICHTENHEFT.md)** - Funktionale Spezifikation
- **[ğŸ‘¥ Benutzerhandbuch](docs/customer/BENUTZERHANDBUCH.md)** - Anleitung fÃ¼r Endnutzer

---

## âš¡ Quick Start

### Voraussetzungen
- Docker & Docker Compose
- Telegram Bot Token (von [@BotFather](https://t.me/BotFather))
- Ollama (lokal oder remote)

### 1. Repository klonen
```bash
git clone https://github.com/Natashick/telegram-chat-bot.git
cd telegram-chat-bot
```

### 2. Umgebung konfigurieren
```bash
cat > .env << 'EOF'
TELEGRAM_TOKEN=your_bot_token_here
WEBHOOK_URL=https://your-domain.com/
OLLAMA_URL=http://host.docker.internal:11434
OLLAMA_MODEL=qwen2.5:7b-instruct
EOF
```

### 3. PDFs hinzufÃ¼gen
```bash
mkdir -p pdfs
cp /path/to/your/documents/*.pdf pdfs/
```

### 4. Ollama starten
```bash
ollama pull qwen2.5:7b-instruct
ollama serve
```

### 5. Bot starten
```bash
docker-compose up -d --build
```

### 6. ÃœberprÃ¼fen
```bash
# Health check
curl http://localhost:8000/health

# Logs ansehen
docker-compose logs -f bot
```

### 7. Bot testen
1. Ã–ffnen Sie Telegram
2. Suchen Sie Ihren Bot
3. Senden Sie `/start`
4. Stellen Sie eine Frage!

**Detaillierte Anleitung**: Siehe [Deployment Guide](docs/technical/02_DEPLOYMENT_GUIDE.md)

---

## âœ¨ Features im Detail

### Kernfunktionen

âœ… **Fragen in natÃ¼rlicher Sprache**
- Stellen Sie Fragen wie "Was ist ISO 21434?"
- Automatische Spracherkennung (DE/EN)
- Kontextbasierte Antworten

âœ… **Intelligente Dokumentensuche**
- Semantische Suche Ã¼ber alle PDFs
- Akronym-Erkennung (TARA, CAN, ECU, etc.)
- Glossar-Priorisierung
- Multi-Dokument-Retrieval

âœ… **Erweiterte Funktionen**
- `/screenshot <doc> <page>` - Seite als Bild
- `/page <doc> <page>` - Textextraktion
- `/status` - Systemstatus & Indexierung
- Automatische Pagination bei langen Antworten

âœ… **Datenschutz & Sicherheit**
- 100% lokale LLM-Verarbeitung (Ollama)
- Keine externen API-Aufrufe (auÃŸer Telegram)
- Telemetrie deaktiviert
- Log-Sanitization fÃ¼r sensible Daten

---

## ğŸ—ï¸ Architektur

```
Telegram User
    â”‚
    â–¼
FastAPI Webhook
    â”‚
    â”œâ”€â–º Message Handlers â”€â”€â–º Retrieval System â”€â”€â–º Vector Store (ChromaDB)
    â”‚                                 â”‚
    â”‚                                 â–¼
    â””â”€â–º LLM Client (Ollama) â—„â”€â”€â”€ PDF Parser
                                      â”‚
                                      â–¼
                                  PDF Files
```

**Technologie-Stack**:
- **Backend**: Python 3.11, FastAPI, python-telegram-bot
- **LLM**: Ollama (lokal, GPU-optional)
- **Vector DB**: ChromaDB (persistent)
- **Embeddings**: sentence-transformers (CPU)
- **PDF Processing**: PyPDF2, pdfplumber, Tesseract OCR
- **Deployment**: Docker + Docker Compose

**Details**: Siehe [System Architecture](docs/technical/01_SYSTEM_ARCHITECTURE.md)

---

## ğŸ”§ Konfiguration

Alle Konfigurationsoptionen sind Ã¼ber Umgebungsvariablen steuerbar:

| Variable | Default | Beschreibung |
|----------|---------|--------------|
| `TELEGRAM_TOKEN` | - | Bot Token (erforderlich) |
| `WEBHOOK_URL` | - | Webhook URL (erforderlich) |
| `OLLAMA_URL` | `http://localhost:11434` | Ollama Endpoint |
| `OLLAMA_MODEL` | `llama3.2:1b` | LLM Modell |
| `CHUNK_SIZE` | `800` | WÃ¶rter pro Chunk |
| `MAX_EXCERPTS` | `12` | Max. Chunks an LLM |
| `OCR_ENABLED` | `0` | OCR aktivieren (1/0) |

**VollstÃ¤ndige Referenz**: [Configuration Guide](docs/technical/04_CONFIGURATION.md)

---

## ğŸš€ Deployment-Optionen

### Option 1: Docker Compose (Empfohlen)
```bash
docker-compose up -d --build
```

### Option 2: Kubernetes
```bash
kubectl apply -f k8s/
```

### Option 3: Bare Metal
```bash
pip install -r requirements.txt
python -m uvicorn bot:app --host 0.0.0.0 --port 8000
```

**Detaillierte Anleitungen**: [Deployment Guide](docs/technical/02_DEPLOYMENT_GUIDE.md)

---

## ğŸ“Š Performance

| Metrik | Wert | Bedingung |
|--------|------|-----------|
| Antwortzeit | 5-15s | Durchschnitt |
| Indexierung | 100-500 Seiten/min | Ohne OCR |
| Vector Search | 50-200ms | 1000s Chunks |
| Concurrent Users | 10-50 | Konfigurierbar |
| Memory | 4-12 GB | AbhÃ¤ngig vom Modell |

**Tuning**: Siehe [Configuration Guide - Performance](docs/technical/04_CONFIGURATION.md#4-performance-tuning)

---

## ğŸ›¡ï¸ Sicherheit & Datenschutz

âœ… **Keine externe DatenÃ¼bertragung**
- LLM lÃ¤uft lokal (Ollama)
- Embeddings lokal generiert
- Keine Cloud-API-Aufrufe

âœ… **Datenschutz-Features**
- ChromaDB-Telemetrie deaktiviert
- Token-Zensierung in Logs
- Webhook-Secret-Validierung
- Message Protection aktiviert

âœ… **DSGVO-konform**
- Lokale Speicherung
- Keine Nutzerprofile
- Keine Tracking-Mechanismen

**Details**: Siehe [Benutzerhandbuch - Datenschutz](docs/customer/BENUTZERHANDBUCH.md#9-datenschutz--sicherheit)

---

## ğŸ“± Nutzung

### Befehle

| Befehl | Beschreibung |
|--------|--------------|
| `/start` | Bot starten |
| `/help` | Hilfe anzeigen |
| `/status` | Systemstatus prÃ¼fen |
| `/screenshot <doc> <page>` | Seite als Bild |
| `/page <doc> <page>` | Text extrahieren |

### Beispiel-Fragen

```
"Was ist TARA in ISO 21434?"
"ErklÃ¤re den Unterschied zwischen CAL 1 und CAL 4"
"Wie fÃ¼hre ich eine Risikoanalyse durch?"
"Was bedeutet ECU im Automotive-Kontext?"
```

**VollstÃ¤ndige Anleitung**: [Benutzerhandbuch](docs/customer/BENUTZERHANDBUCH.md)

---

## ğŸ§ª Testing

```bash
# Unit tests
pytest tests/

# Integration tests
pytest tests/ -m integration

# E2E tests
pytest tests/ -m e2e

# Coverage
pytest --cov=. --cov-report=html
```

**Test-Konzept**: Siehe [Pflichtenheft - Testkonzept](docs/pflichtenheft/PFLICHTENHEFT.md#7-testkonzept)

---

## ğŸ¤ Beitragen

BeitrÃ¤ge sind willkommen! Bitte beachten Sie:

1. Fork das Repository
2. Erstellen Sie einen Feature-Branch (`git checkout -b feature/AmazingFeature`)
3. Commit Ihre Ã„nderungen (`git commit -m 'Add AmazingFeature'`)
4. Push zum Branch (`git push origin feature/AmazingFeature`)
5. Ã–ffnen Sie einen Pull Request

**Contribution Guidelines**: Siehe [CONTRIBUTING.md](CONTRIBUTING.md) (falls vorhanden)

---

## ğŸ“„ Lizenz

Dieses Projekt ist unter der MIT-Lizenz lizenziert - siehe [LICENSE](LICENSE) fÃ¼r Details.

---

## ğŸ™ Danksagungen

- **Ollama** - Lokales LLM Framework
- **ChromaDB** - Vector Database
- **python-telegram-bot** - Telegram Bot Framework
- **sentence-transformers** - Embedding Models
- **FastAPI** - Web Framework

---

## ğŸ“ Support & Kontakt

- **Dokumentation**: [docs/](docs/README.md)
- **Issues**: [GitHub Issues](https://github.com/Natashick/telegram-chat-bot/issues)
- **Repository**: [github.com/Natashick/telegram-chat-bot](https://github.com/Natashick/telegram-chat-bot)

---

## ğŸ—ºï¸ Roadmap

### Geplante Features
- [ ] Multi-User Support mit Dokumenten-Isolation
- [ ] Admin-Panel fÃ¼r Dokumentenverwaltung
- [ ] Export von Konversationen
- [ ] Erweiterte Filter-Optionen
- [ ] GPU-Beschleunigung fÃ¼r Embeddings
- [ ] Weitere Sprachen (FR, ES, IT)

**Details**: Siehe [Lastenheft - Wunschkriterien](docs/lastenheft/LASTENHEFT.md#12-wunschkriterien)

---

## ğŸ“ˆ Changelog

### Version 1.0 (2026-01-27)
- âœ¨ Initiale VerÃ¶ffentlichung
- ğŸ“š VollstÃ¤ndige Dokumentation (Lastenheft, Pflichtenheft, Benutzerhandbuch)
- ğŸ” Semantische PDF-Suche
- ğŸ¤– Ollama LLM Integration
- ğŸ³ Docker Deployment
- ğŸŒ Deutsch/Englisch Support

---

**Made with â¤ï¸ for secure, privacy-focused document search**

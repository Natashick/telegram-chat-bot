# Telegram Bot API token (get from @BotFather)
TELEGRAM_TOKEN=

# Public webhook URL for the bot (set your Railway or Render public domain)
WEBHOOK_URL=

# Enable OCR for PDFs (1 = enabled, 0 = disabled)
OCR_ENABLED=0

# Enable title-based indexing (1 = enabled, 0 = disabled)
ENABLE_TITLE_INDEX=0

# Batch size for vector embedding
EMBED_BATCH_SIZE=16

# Enable pre-indexing (1 = enabled, 0 = disabled)
PREINDEX_ENABLED=1

# Number of concurrent indexing jobs
INDEX_CONCURRENCY=2

# Max concurrent updates during indexing
MAX_UPDATE_CONCURRENCY=10

# Max number of chunks per index (0 = unlimited)
MAX_INDEX_CHUNKS=0

# Chunk size for PDF splitting (words)
CHUNK_SIZE=800

# Overlap size between chunks (words)
CHUNK_OVERLAP=200

# Processing batch size for embeddings
BATCH_SIZE=1

# Ollama LLM service URL (if using a local/remote LLM)
OLLAMA_URL=

# Ollama model name
OLLAMA_MODEL=llama3.2:1b

# Context window size for LLM (tokens)
OLLAMA_NUM_CTX=1024

# Enable stream response from Ollama (1 = enabled)
OLLAMA_STREAM=1

# Sentence-transformers embedding model name
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Opt-out of anonymized usage telemetry
ANONYMIZED_TELEMETRY=False

# Minimum similarity threshold for vector search
MIN_SIM_THRESHOLD=0.15

# Maximum noise ratio allowed by OCR (float, e.g. 0.7)
OCR_NOISE_MAX_RATIO=0.7

# Number of Gunicorn workers (if used for FastAPI)
GUNICORN_WORKERS=1

# Application log level
LOG_LEVEL=INFO

# Protect content from forwarding in Telegram (1 = enabled)
PROTECT_CONTENT=1

# (For private PDF repo integration)
PDF_REPO_URL=
PDF_REPO_TOKEN=

# (For persistent ChromaDB)
CHROMA_DB_PATH=./chroma_db
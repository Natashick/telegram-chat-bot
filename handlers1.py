# handlers.py
import os
import re
import logging
import asyncio
from typing import Dict, List
import io
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, ReplyKeyboardMarkup, KeyboardButton
from telegram.constants import ChatAction, ParseMode
from telegram.ext import ContextTypes

from indexer import schedule_index, preindex_running, preindex_done, preindex_total  # import scheduling helper
from retrieval import (
    get_best_chunks_for_document,
    get_best_chunks_global,
    build_combined_excerpts,
    detect_acronym,
    find_definition_in_chunks,
    find_chunk_with_term,
)
from vector_store import vector_store
from llm_client import ask_ollama

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Protokollierungsfilter (Schutz sensibler Informationen in Protokollen) ---
_WEBHOOK_SECRET = os.getenv("WEBHOOK_SECRET", "")  # Geheimnis aus ENV f√ºr Webhook‚ÄëPfad
_PDF_DIR_ENV = os.getenv("PDF_DIR", "")  # Optionaler PDF‚ÄëStammpfad aus ENV

def _censor(text: str) -> str:
    # Ersetzt sensible Muster (Tokens, Secrets, Pfade) durch in Logstrings
    if not text:  # Leere Eingabe unver√§ndert zur√ºckgeben
        return text
    s = str(text)  # Robustheit: beliebigen Typ in String wandeln
    # Liste zensierbarer Muster
    patterns = [
        r"\b\d{8,}:[A-Za-z0-9_\-]{20,}\b",                  # Telegram‚ÄëBot‚ÄëToken‚Äë√§hnliches Muster
        r"(?:https?://)?[a-z0-9\-]+\.ngrok-free\.app[^\s]*", # ngrok‚ÄëURL (inkl. Pfad/Query)
        re.escape(_WEBHOOK_SECRET) if _WEBHOOK_SECRET else None,  # konkretes Webhook‚ÄëSecret
        r"[A-Za-z]:\\[^\s]+",                                # absolute Windows‚ÄëPfade
        r"/app/pdfs/[^\s]+",                                 # Container‚ÄëPDF‚ÄëPfad
    ]
    for pat in filter(None, patterns):  # None auslassen, falls optionales Muster fehlt
        s = re.sub(pat, "[CENSORED]", s, flags=re.IGNORECASE)  # fallunabh√§ngige Ersetzung
    return s  # zensierter String

class _CensorFilter(logging.Filter):
    # Logging‚ÄëFilter: erzwingt Zensur auf der fertigen Lognachricht und typischen Zusatzfeldern
    def filter(self, record: logging.LogRecord) -> bool:
        try:
            msg = record.getMessage()          # formatierten Nachrichtentext erzeugen
            record.msg = _censor(msg)          # sensiblen Inhalt durch Platzhalter ersetzen
            record.args = ()                   # weitere %-Formatierung verhindern
        except Exception:
            pass                               # Logging darf nie durch Zensurfehler brechen
        # Bestm√∂gliche Bem√ºhungen: Zensur g√§ngiger benutzerdefinierter Attribute
        for attr in ("text", "data"):
            if hasattr(record, attr):          # nur vorhandene Attribute pr√ºfen
                try:
                    val = getattr(record, attr)
                    setattr(record, attr, _censor(val))  # Attributinhalt zensieren
                except Exception:
                    pass
        return True  # Logeintrag weiterreichen (nie blockieren)

logger.addFilter(_CensorFilter())

MAX_EXCERPTS = int(os.getenv("MAX_EXCERPTS", "12"))
PROTECT_CONTENT = os.getenv("PROTECT_CONTENT", "1") == "1"

_SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PDF_DIR = os.getenv('PDF_DIR', _SCRIPT_DIR)
if PDF_DIR == _SCRIPT_DIR:
    PDF_DIR = os.path.join(_SCRIPT_DIR, "pdfs")

# Minimaler lokaler Zustand f√ºr die Paginierung
user_pages_state: Dict[int, Dict] = {}
# Einfacher Screenshot-Zustand pro Benutzer
SCREENSHOT_STATE: Dict[int, Dict] = {}

def _is_screenshot_target_query(text: str) -> bool:
    """Return True if text looks like a page/table/figure reference."""
    if not text:
        return False
    t = text.strip()
    if re.search(r"(?i)\b(seite|page)\s*\d+\b", t):
        return True
    # akzeptiere numerisch (3) und alphanumerisch wie H.3 / H-3 / H3
    if re.search(r"(?i)\b(tab(?:elle)?|table)\s*([A-Za-z]\s*[\.\-]?\s*\d+|\d+)\b", t):
        return True
    if re.search(r"(?i)\b(fig(?:ure)?|abbildung)\s*([A-Za-z]\s*[\.\-]?\s*\d+|\d+)\b", t):
        return True
    return False
def _build_docs_keyboard(pdfs: List[str]) -> InlineKeyboardMarkup:
    buttons = []
    row: List[InlineKeyboardButton] = []
    for idx, p in enumerate(pdfs):
        label = os.path.basename(p)[:30]
        row.append(InlineKeyboardButton(label, callback_data=f"shot_doc:{idx}"))
        if len(row) == 2:
            buttons.append(row)
            row = []
    if row:
        buttons.append(row)
    return InlineKeyboardMarkup(buttons)

 

def get_pdf_files() -> List[str]:
    try:
        entries = os.listdir(PDF_DIR)
    except Exception:
        entries = []
    return [os.path.join(PDF_DIR, f) for f in entries if f.lower().endswith('.pdf')]

# --- Befehle (d√ºnne Wrapper) ---

async def start_command(update: Update, _context: ContextTypes.DEFAULT_TYPE):
    pdfs = get_pdf_files()
    if not pdfs:
        await update.message.reply_text("Keine PDFs gefunden. Bitte lade zuerst PDFs hoch.", disable_web_page_preview=True)
        return
    main_kb = ReplyKeyboardMarkup(
        [[KeyboardButton("/start"), KeyboardButton("/screenshot")]],
        resize_keyboard=True,
        one_time_keyboard=False,
        is_persistent=True
    )
    await update.message.reply_text(
        "Willkommen beim Automotive-Cybersecurity-Bot.\n\n"
        "So funktioniert es:\n"
        "1Ô∏è‚É£ Dr√ºcke /Start.\n"
        "2Ô∏è‚É£ Stelle deine Frage oder nutze /screenshot f√ºr Seiten/Bilder/Tabellen.\n"
        "‚ö†Ô∏è Hinweis: Die Dokumenteninhalte sind vertraulich. Bitte keine Screenshots speichern oder weitergeben.",
        reply_markup=main_kb,
        disable_web_page_preview=True,
    )

async def help_command(update: Update, _context: ContextTypes.DEFAULT_TYPE):
    main_kb = ReplyKeyboardMarkup(
        [[KeyboardButton("/start"), KeyboardButton("/screenshot")]],
        resize_keyboard=True,
        one_time_keyboard=False,
        is_persistent=True
    )
    await update.message.reply_text(
        "Hilfe: /start (Startmen√º) ‚Ä¢ /status (Index) ‚Ä¢ /screenshot (Seite/Bild/Tabelle).",
        reply_markup=main_kb,
        disable_web_page_preview=True
    )

async def status_command(update: Update, _context: ContextTypes.DEFAULT_TYPE):
    info = await asyncio.to_thread(vector_store.get_document_info)
    text = (
        f"VectorStore chunks: {info.get('total_chunks', 'unknown')}\n"
        f"Persist dir: {info.get('persist_directory', 'unknown')}\n"
        f"Preindex: running={preindex_running}, done={preindex_done}/{preindex_total}\n"
    )
    await update.message.reply_text(text, disable_web_page_preview=True)

async def button_callback(update: Update, _context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    try:
        await q.answer()
    except Exception:
        pass
    # Paginierung f√ºr lange Antworten
    if q.data in ("page_prev", "page_next"):
        st = user_pages_state.get(q.from_user.id) or {}
        pages = st.get("pages") or []
        if not pages:
            return
        old_idx = st.get("idx", 0)
        idx = old_idx
        if q.data == "page_prev":
            idx = max(0, idx - 1)
        else:
            idx = min(len(pages) - 1, idx + 1)
        # Vermeide Telegram BadRequest "Message is not modified"
        if idx == old_idx:
            return
        st["idx"] = idx
        user_pages_state[q.from_user.id] = st
        kb = InlineKeyboardMarkup([[InlineKeyboardButton("‚óÄÔ∏è Prev", callback_data="page_prev"),
                                    InlineKeyboardButton("‚ñ∂Ô∏è Next", callback_data="page_next")]])
        await q.edit_message_text(pages[idx] + f"\n\nüìÑ {idx+1}/{len(pages)}", reply_markup=kb, disable_web_page_preview=True)
        return
    if q.data == "shot_start":
        # start document selection
        pdfs = get_pdf_files()
        SCREENSHOT_STATE[q.from_user.id] = {"mode": "pick_doc"}
        kb = _build_docs_keyboard(pdfs)
        await q.edit_message_text(
            "üìÑ Bitte w√§hlen Sie ein Dokument f√ºr den Screenshot:",
            reply_markup=kb,
            disable_web_page_preview=True
        )
        return
    if q.data.startswith("shot_doc:"):
        try:
            _, idx_s = q.data.split(":", 1)
            idx = int(idx_s)
        except Exception:
            await q.answer("Ung√ºltige Auswahl")
            return
        pdfs = get_pdf_files()
        if not (0 <= idx < len(pdfs)):
            await q.answer("Dokument nicht gefunden")
            return
        doc_path = pdfs[idx]
        SCREENSHOT_STATE[q.from_user.id] = {"mode": "awaiting_target", "doc": doc_path}
        back_kb = InlineKeyboardMarkup([[InlineKeyboardButton("‚óÄÔ∏è Dokument w√§hlen", callback_data="shot_start")]])
        await q.edit_message_text(
            f"Ausgew√§hlt: {os.path.basename(doc_path)}\n"
            "Geben Sie ein, was gerendert werden soll, z.B.:\n"
            "‚Ä¢ ‚ÄûSeite 10‚Äú oder ‚ÄûPage 10‚Äú\n"
            "‚Ä¢ ‚ÄûTabelle 3‚Äú / ‚ÄûTable 3‚Äú oder ‚ÄûAbbildung 2‚Äú / ‚ÄûFigure 2‚Äú\n"
            "‚Ä¢ oder einen Titel-/Kapiteltext",
            reply_markup=back_kb,
            disable_web_page_preview=True
        )
        return
    if q.data.startswith("shot_goto:"):
        # syntax: shot_goto:<idx>:<page>
        try:
            _, idx_s, page_s = q.data.split(":", 2)
            idx = int(idx_s); page = int(page_s)
        except Exception:
            await q.answer("Ung√ºltige Auswahl")
            return
        pdfs = get_pdf_files()
        if not (0 <= idx < len(pdfs)):
            await q.answer("Dokument nicht gefunden")
            return
        from pdf_parser import get_page_image_bytes
        img = get_page_image_bytes(pdfs[idx], page)
        if not img:
            await q.edit_message_text("Seite konnte nicht gerendert werden.", disable_web_page_preview=True)
            return
        await _context.bot.send_photo(
            chat_id=update.effective_chat.id,
            photo=io.BytesIO(img),
            caption=f"üìÑ {os.path.basename(pdfs[idx])} ‚Äì Seite {page}",
            protect_content=PROTECT_CONTENT,
        )
        return
    if q.data == "start_query":
        await q.edit_message_text("Stelle deine Frage:", disable_web_page_preview=True)
        return

# --- Paginierungshilfen (klein) ---

def _split_pages(text: str, max_len: int = 3600) -> List[str]:
    if len(text) <= max_len:
        return [text]
    pages = []
    start = 0
    while start < len(text):
        end = min(len(text), start + max_len)
        pages.append(text[start:end])
        start = end
    return pages

async def _send_paginated(update: Update, _context: ContextTypes.DEFAULT_TYPE, text: str):
    user_id = update.effective_user.id
    pages = _split_pages(text)
    try:
        if len(pages) == 1:
            await update.message.reply_text(
                pages[0],
                disable_web_page_preview=True,  # keine Link-Vorschau erlauben
                parse_mode=ParseMode.HTML,
                protect_content=PROTECT_CONTENT,  # Telegram‚ÄëSchutzflag
            )
            return

        user_pages_state[user_id] = {'pages': pages, 'idx': 0}
        kb = InlineKeyboardMarkup(
            [
                [
                    InlineKeyboardButton("‚óÄÔ∏è Prev", callback_data="page_prev"),
                    InlineKeyboardButton("‚ñ∂Ô∏è Next", callback_data="page_next"),
                ]
            ]
        )
        msg = await update.message.reply_text(
            pages[0] + f"\n\nüìÑ 1/{len(pages)}",
            reply_markup=kb,
            disable_web_page_preview=True,
            parse_mode=ParseMode.HTML,
            protect_content=PROTECT_CONTENT,
        )
        user_pages_state[user_id]['last_message_id'] = msg.message_id
    except Exception as e:
        logger.warning(f"Send failed: {e}")
        if len(pages) == 1:
            await update.message.reply_text(
                pages[0],
                parse_mode=ParseMode.HTML,
                disable_web_page_preview=True,
                protect_content=PROTECT_CONTENT,
            )
            return
        user_pages_state[user_id] = {'pages': pages, 'idx': 0}
        kb = InlineKeyboardMarkup(
            [
                [
                    InlineKeyboardButton("‚óÄÔ∏è Prev", callback_data="page_prev"),
                    InlineKeyboardButton("‚ñ∂Ô∏è Next", callback_data="page_next"),
                ]
            ]
        )
        msg = await update.message.reply_text(
            pages[0] + f"\n\nüìÑ 1/{len(pages)}",
            reply_markup=kb,
            parse_mode=ParseMode.HTML,
            disable_web_page_preview=True,
            protect_content=PROTECT_CONTENT,
        )
        user_pages_state[user_id]['last_message_id'] = msg.message_id

# --- Kernnachrichten-Handler (d√ºnn, verwendet Retrieval/Indexer) ---

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):

    user_question = (update.message.text or "").strip()
    if not user_question:
        return
    user_id = update.effective_user.id
    logger.info("Question from %s: %s", user_id, user_question)

    # --- Screenshot-Modus (fr√ºhe Verarbeitung) ---
    _shot = SCREENSHOT_STATE.get(user_id, {})
    # Nur abfangen, wenn der Benutzer sich im Screenshot-Zielmodus befindet UND der Text wie eine Zielabfrage aussieht.
    if _shot.get("mode") in ("awaiting_target",) and _is_screenshot_target_query(user_question):
        from pdf_parser import get_page_image_bytes, extract_titles_from_pdf
        doc_path = _shot.get("doc")
        if not doc_path or not os.path.exists(doc_path):
            SCREENSHOT_STATE[user_id] = {"mode": "pick_doc"}
            kb = _build_docs_keyboard(get_pdf_files())
            await update.message.reply_text("Bitte w√§hlen Sie ein Dokument:", reply_markup=kb, disable_web_page_preview=True)
            return
        txt = user_question.strip()
        # 1) explizite Seitenzahl
        # Akzeptiere "Seite 10" oder "Page 10" (Gro√ü-/Kleinschreibung ignorieren)
        m = re.search(r"(?i)\b(seite|page)\s*(\d+)", txt)
        if m:
            page = int(m.group(2))
            try:
                img = get_page_image_bytes(doc_path, page)
            except Exception as e:
                logger.debug("get_page_image_bytes error: %s", e)
                img = b""
            if not img:
                await update.message.reply_text("Seite konnte nicht gerendert werden.", disable_web_page_preview=True)
                return
            SCREENSHOT_STATE.pop(user_id, None)
            await context.bot.send_photo(
                update.effective_chat.id,
                io.BytesIO(img),
                caption=f"üìÑ {os.path.basename(doc_path)} ‚Äì Seite {page}",
                protect_content=PROTECT_CONTENT,
            )
            return
        # 2) Tabelle / Abbildung nach Nummer
        titles = []
        try:
            titles = extract_titles_from_pdf(doc_path)
        except Exception:
            titles = []
        m_tbl = re.search(r"(?i)\b(tab(?:elle)?|table)\s*([A-Za-z]\s*[\.\-]?\s*\d+|\d+)", txt)
        m_fig = re.search(r"(?i)\b(fig(?:ure)?|abbildung)\s*([A-Za-z]\s*[\.\-]?\s*\d+|\d+)", txt)
        if m_tbl:
            num = m_tbl.group(2)
            def _norm(s: str) -> str:
                return re.sub(r"[\\s\\.\\-]+", "", (s or "").lower())
            num_n = _norm(num)
            cand = next((t for t in titles if t.get('type','').lower() in ('table','tabelle') and num_n in _norm(t.get('title',''))), None)
            if cand:
                page = int(cand.get('page', 1))
                img = get_page_image_bytes(doc_path, page)
                if not img:
                    await update.message.reply_text("Seite konnte nicht gerendert werden.", disable_web_page_preview=True)
                    return
                SCREENSHOT_STATE.pop(user_id, None)
                await context.bot.send_photo(
                    update.effective_chat.id,
                    io.BytesIO(img),
                    caption=f"üìÑ {os.path.basename(doc_path)} ‚Äì Seite {page}: {cand.get('title','')}",
                    protect_content=PROTECT_CONTENT,
                )
                return
        if m_fig:
            num = m_fig.group(2)
            def _norm2(s: str) -> str:
                return re.sub(r"[\\s\\.\\-]+", "", (s or "").lower())
            num_n = _norm2(num)
            cand = next((t for t in titles if t.get('type','').lower() in ('figure','abbildung') and num_n in _norm2(t.get('title',''))), None)
            if cand:
                page = int(cand.get('page', 1))
                img = get_page_image_bytes(doc_path, page)
                if not img:
                    await update.message.reply_text("Seite konnte nicht gerendert werden.", disable_web_page_preview=True)
                    return
                SCREENSHOT_STATE.pop(user_id, None)
                await context.bot.send_photo(
                    update.effective_chat.id,
                    io.BytesIO(img),
                    caption=f"üìÑ {os.path.basename(doc_path)} ‚Äì Seite {page}: {cand.get('title','')}",
                    protect_content=PROTECT_CONTENT,
                )
                return
        # 3) Stichwortsuche in Titeln
        kw = txt.lower()
        hits = [t for t in titles if kw and kw in (t.get('title','').lower())]
        if not hits:
            await update.message.reply_text("Kein Treffer. Beispiele: ‚ÄûSeite 10‚Äú, ‚ÄûTabelle 3‚Äú, ‚ÄûFigure 2‚Äú oder ein Stichwort aus dem Titel.", disable_web_page_preview=True)
            return
        if len(hits) == 1:
            page = int(hits[0].get('page', 1))
            img = get_page_image_bytes(doc_path, page)
            if not img:
                await update.message.reply_text("Seite konnte nicht gerendert werden.", disable_web_page_preview=True)
                return
            SCREENSHOT_STATE.pop(user_id, None)
            await context.bot.send_photo(
                update.effective_chat.id,
                io.BytesIO(img),
                caption=f"üìÑ {os.path.basename(doc_path)} ‚Äì Seite {page}: {hits[0].get('title','')}",
                protect_content=PROTECT_CONTENT,
            )
            return
        # Auswahl anbieten
        pdfs = get_pdf_files()
        try:
            doc_idx = pdfs.index(doc_path)
        except ValueError:
            doc_idx = 0
        rows = [[InlineKeyboardButton(f"S.{int(h.get('page',1))}: {h.get('title','')[:40]}", callback_data=f"shot_goto:{doc_idx}:{int(h.get('page',1))}")] for h in hits[:10]]
        kb = InlineKeyboardMarkup(rows + [[InlineKeyboardButton("‚óÄÔ∏è Dokument w√§hlen", callback_data="shot_start")]])
        await update.message.reply_text("Mehrere Treffer ‚Äì bitte w√§hlen:", reply_markup=kb, disable_web_page_preview=True)
        return
    # Wenn der Benutzer sich im Screenshot-Fluss befindet, aber eine normale Frage eingibt, den Screenshot-Modus verlassen und mit Q/A fortfahren.
    if _shot.get("mode") in ("awaiting_target","pick_doc") and not user_question.startswith("/screenshot"):
        SCREENSHOT_STATE.pop(user_id, None)

    # Sprachrichtlinie: Standard EN; wenn die Frage wie Deutsch aussieht, antworte DE
    t = f" {(user_question or '').casefold()} "
    is_german = any(w in t for w in (
        " was ", " ist ", " sind ", " sollte ", " wie ", " wann ", " warum ",
        " worum ", " worauf ", " inwiefern ", " der ", " die ", " das ", " √ºber ", " und "
    )) or any(ch in user_question for ch in ("√§","√∂","√º","√Ñ","√ñ","√ú","√ü"))
    context.user_data["lang"] = "DE" if is_german else "EN"

    # Schneller Check: Wenn keine PDFs indexiert sind, Indexierung planen und Benutzer informieren
    pdfs = get_pdf_files()
    if not pdfs:
        await update.message.reply_text("Keine PDFs vorhanden.")
        return

    # Sicherstellen, dass mindestens ein Dokument indexiert ist; falls nicht, Indexierung planen und Benutzer auffordern, es sp√§ter erneut zu versuchen
    has_any = await asyncio.to_thread(lambda: any(vector_store.has_document(p) for p in pdfs))
    if not has_any:
        # Indexierung f√ºr alle PDFs planen und Benutzer auffordern, es sp√§ter erneut zu versuchen
        for p in pdfs:
            schedule_index(p)
        await update.message.reply_text(
            "Indexierung gestartet im Hintergrund. Pr√ºfe den Fortschritt mit /status und versuche es danach erneut.",
            disable_web_page_preview=True,
        )
        return

    # Global beste Abschnitte √ºber alle Dokumente hinweg, um Pr√§zision und Recall zu maximieren
    try:
        all_chunks = await get_best_chunks_global(user_question, max_chunks=MAX_EXCERPTS)
    except Exception as e:
        logger.debug("Global retrieval error: %s", e)
    all_chunks = []

    # Fallback: wenn zu wenige globale Ergebnisse vorliegen, pro Dokument parallel abfragen
    if not all_chunks or len(all_chunks) < max(4, MAX_EXCERPTS // 2):
        try:
            tasks = [
                get_best_chunks_for_document(user_question, p, max_chunks=max(4, MAX_EXCERPTS // 2))
                for p in pdfs
            ]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            combined: List[dict] = []
            for res in results:
                if isinstance(res, Exception):
                    logger.debug("Error fetching chunks: %s", res)
                    continue
                if res:
                    combined.extend(res)
            # Duplikate entfernen + sortieren
            seen = set()
            uniq = []
            for c in combined:
                key = f"{c.get('chunk_id')}|{(c.get('text') or '')[:64]}"
                if key in seen:
                    continue
                seen.add(key)
                uniq.append(c)
            all_chunks = sorted(uniq, key=lambda c: c.get("similarity_score", 0), reverse=True)[:MAX_EXCERPTS]
        except Exception as e:
            logger.debug("Parallel per-doc retrieval error: %s", e)

    if not all_chunks:
        await update.message.reply_text("Keine relevanten Informationen gefunden.")
        return

    # Versuch deterministisches 'Definition zuerst' Verhalten
    term = detect_acronym(user_question)
    if term:
        defs = find_definition_in_chunks(term, all_chunks)
        if defs:
            # Gefundene Definitionen √ºber LLM umformulieren (ohne rohe Zitate)
            combined_context = "\n\n".join([(d.get("text") or "").strip() for d in defs[:3]])
            await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)
            try:
                answer = await ask_ollama(user_question, combined_context, defs[:3], target_language=context.user_data.get("lang", "DE"))
            except Exception as e:
                logger.exception("LLM paraphrase error: %s", e)
                await update.message.reply_text("Fehler beim Generieren der Antwort.")
                return
            await _send_paginated(update, context, answer)
            return
        # Wenn eine genaue Zitat mit dem Begriff gefunden wird
        exact = find_chunk_with_term(term, all_chunks)
        if exact:
            await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)
            try:
                answer = await ask_ollama(user_question, exact, [{"text": exact}], target_language=context.user_data.get("lang", "DE"))
            except Exception as e:
                logger.exception("LLM paraphrase error for exact chunk: %s", e)
                await update.message.reply_text("Fehler beim Generieren der Antwort.")
                return
            await _send_paginated(update, context, answer)
            return

    # Fallback: kombinierte Ausz√ºge vorbereiten und LLM mit strengem Prompt aufrufen
    # Anzahl der gesendeten Ausz√ºge begrenzen
    final_chunks = sorted(all_chunks, key=lambda c: c.get("similarity_score", 0), reverse=True)[:MAX_EXCERPTS]

    # Hinweis statt harter Blockade: Wenn das Akronym eindeutig nicht gefunden wird, versuchen wir trotzdem, die Frage zu beantworten.
    if term and re.fullmatch(r"[A-Z√Ñ√ñ√ú]{2,5}", term or ""):
        joined = " ".join((c.get("text") or "") for c in final_chunks) or ""
        if not re.search(rf"(?<![A-Za-z√Ñ√ñ√ú√§√∂√º√ü]){re.escape(term)}(?![A-Za-z√Ñ√ñ√ú√§√∂√º√ü])", joined):
            # keine Unterbrechung der Antwort; das Modell kann trotzdem eine n√ºtzliche kurze Erkl√§rung geben
            pass
    combined = build_combined_excerpts(final_chunks)
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)
    try:
        answer = await ask_ollama(user_question, combined, final_chunks, target_language=context.user_data.get("lang", "DE"))
    except Exception as e:
        logger.exception("LLM call failed: %s", e)
        await update.message.reply_text("Fehler beim Generieren der Antwort.")
        return

    await _send_paginated(update, context, answer)

# --- Einfacher Screenshot-Befehl Platzhalter ---

async def screenshot_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # Beginnen Sie mit der Dokumentauswahl
    SCREENSHOT_STATE[update.effective_user.id] = {"mode": "pick_doc"}
    kb = _build_docs_keyboard(get_pdf_files())
    await update.message.reply_text(
        "Screenshot-Modus aktiviert.\n"
        "üìÑ Bitte w√§hlen Sie ein Dokument f√ºr den Screenshot.",
        reply_markup=kb,
        disable_web_page_preview=True,
    )